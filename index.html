<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ML/DS/Quant Interview Prep</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #f5f7fa 0%, #e4e9f2 100%);
            min-height: 100vh;
            padding: 20px;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
        }
        
        .header {
            text-align: center;
            margin-bottom: 40px;
        }
        
        .header h1 {
            font-size: 2.5rem;
            color: #1e293b;
            margin-bottom: 10px;
        }
        
        .header p {
            color: #64748b;
            font-size: 1.1rem;
        }
        
        .resource-btn {
            margin-top: 15px;
            padding: 12px 24px;
            background: #f97316;
            color: white;
            border: none;
            border-radius: 8px;
            font-size: 1rem;
            cursor: pointer;
            transition: background 0.3s;
        }
        
        .resource-btn:hover {
            background: #ea580c;
        }
        
        .categories {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            justify-content: center;
            margin-bottom: 30px;
        }
        
        .category-btn {
            padding: 12px 20px;
            border: none;
            border-radius: 8px;
            font-size: 1rem;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.3s;
            background: white;
            color: #334155;
        }
        
        .category-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0,0,0,0.1);
        }
        
        .category-btn.active {
            color: white;
            box-shadow: 0 4px 12px rgba(0,0,0,0.15);
        }
        
        .category-btn.blue.active { background: #3b82f6; }
        .category-btn.red.active { background: #ef4444; }
        .category-btn.green.active { background: #10b981; }
        .category-btn.purple.active { background: #8b5cf6; }
        .category-btn.orange.active { background: #f97316; }
        .category-btn.pink.active { background: #ec4899; }
        
        .progress-section {
            background: white;
            padding: 20px;
            border-radius: 12px;
            margin-bottom: 30px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }
        
        .progress-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 10px;
        }
        
        .progress-text {
            font-weight: 500;
            color: #334155;
        }
        
        .reset-btn {
            background: none;
            border: none;
            color: #64748b;
            cursor: pointer;
            font-size: 0.9rem;
        }
        
        .reset-btn:hover {
            color: #334155;
        }
        
        .progress-bar {
            width: 100%;
            height: 12px;
            background: #e2e8f0;
            border-radius: 6px;
            overflow: hidden;
        }
        
        .progress-fill {
            height: 100%;
            background: #3b82f6;
            transition: width 0.3s ease;
            border-radius: 6px;
        }
        
        .card {
            background: white;
            border-radius: 16px;
            padding: 40px;
            margin-bottom: 30px;
            min-height: 400px;
            box-shadow: 0 4px 16px rgba(0,0,0,0.1);
            display: flex;
            flex-direction: column;
            justify-content: space-between;
        }
        
        .card-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 20px;
        }
        
        .card-number {
            color: #64748b;
            font-size: 0.9rem;
        }
        
        .complete-btn {
            padding: 8px 16px;
            border: none;
            border-radius: 6px;
            font-size: 0.9rem;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.3s;
            background: #f1f5f9;
            color: #64748b;
        }
        
        .complete-btn:hover {
            background: #e2e8f0;
        }
        
        .complete-btn.completed {
            background: #dcfce7;
            color: #166534;
        }
        
        .question {
            font-size: 1.5rem;
            font-weight: 700;
            color: #1e293b;
            margin-bottom: 20px;
            line-height: 1.4;
        }
        
        .answer {
            background: #f8fafc;
            padding: 20px;
            border-radius: 8px;
            color: #334155;
            line-height: 1.7;
            white-space: pre-line;
            margin-top: 20px;
        }
        
        .show-answer-btn {
            padding: 12px 24px;
            background: #3b82f6;
            color: white;
            border: none;
            border-radius: 8px;
            font-size: 1rem;
            font-weight: 500;
            cursor: pointer;
            transition: background 0.3s;
            margin-top: 20px;
        }
        
        .show-answer-btn:hover {
            background: #2563eb;
        }
        
        .navigation {
            display: flex;
            justify-content: space-between;
            margin-top: 30px;
        }
        
        .nav-btn {
            padding: 12px 24px;
            border: none;
            border-radius: 8px;
            font-size: 1rem;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.3s;
        }
        
        .nav-btn.prev {
            background: #e2e8f0;
            color: #334155;
        }
        
        .nav-btn.prev:hover:not(:disabled) {
            background: #cbd5e1;
        }
        
        .nav-btn.next {
            background: #334155;
            color: white;
        }
        
        .nav-btn.next:hover {
            background: #1e293b;
        }
        
        .nav-btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }
        
        .stats {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 15px;
        }
        
        .stat-card {
            background: white;
            padding: 20px;
            border-radius: 12px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
            text-align: center;
        }
        
        .stat-icon {
            font-size: 2rem;
            margin-bottom: 8px;
        }
        
        .stat-name {
            font-size: 0.85rem;
            color: #64748b;
            margin-bottom: 5px;
        }
        
        .stat-value {
            font-size: 1.2rem;
            font-weight: 700;
        }
        
        .stat-value.blue { color: #3b82f6; }
        .stat-value.red { color: #ef4444; }
        .stat-value.green { color: #10b981; }
        .stat-value.purple { color: #8b5cf6; }
        .stat-value.orange { color: #f97316; }
        .stat-value.pink { color: #ec4899; }
        
        .resources {
            background: white;
            border-radius: 16px;
            padding: 40px;
            box-shadow: 0 4px 16px rgba(0,0,0,0.1);
        }
        
        .resources h2 {
            font-size: 2rem;
            color: #1e293b;
            margin-bottom: 30px;
        }
        
        .resources h3 {
            font-size: 1.3rem;
            color: #1e293b;
            margin-top: 25px;
            margin-bottom: 15px;
        }
        
        .resources section {
            margin-bottom: 30px;
        }
        
        .resources ul {
            list-style: disc;
            padding-left: 25px;
            color: #64748b;
            line-height: 1.8;
        }
        
        .resources p {
            color: #64748b;
            line-height: 1.7;
            margin-bottom: 10px;
        }
        
        .timeline-item, .format-item {
            padding: 15px;
            border-radius: 8px;
            margin-bottom: 15px;
        }
        
        .timeline-item h4, .format-item h4 {
            font-weight: 700;
            margin-bottom: 8px;
        }
        
        .timeline-item.blue { background: #dbeafe; color: #1e40af; }
        .timeline-item.green { background: #d1fae5; color: #065f46; }
        .timeline-item.orange { background: #fed7aa; color: #9a3412; }
        .timeline-item.red { background: #fee2e2; color: #991b1b; }
        
        .format-item { background: #f8fafc; color: #334155; }
        
        .back-btn {
            padding: 12px 24px;
            background: #475569;
            color: white;
            border: none;
            border-radius: 8px;
            font-size: 1rem;
            cursor: pointer;
            margin-bottom: 30px;
            transition: background 0.3s;
        }
        
        .back-btn:hover {
            background: #334155;
        }
        
        .hidden {
            display: none;
        }
        
        @media (max-width: 768px) {
            .header h1 {
                font-size: 1.8rem;
            }
            
            .card {
                padding: 25px;
                min-height: 350px;
            }
            
            .question {
                font-size: 1.2rem;
            }
            
            .stats {
                grid-template-columns: repeat(2, 1fr);
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <!-- Main Content -->
        <div id="mainContent">
            <div class="header">
                <h1>üéØ Interview Prep Hub</h1>
                <p>ML ‚Ä¢ Deep Learning ‚Ä¢ Data Science ‚Ä¢ GenAI ‚Ä¢ Quant Finance</p>
                <button class="resource-btn" onclick="showResources()">üìö Study Resources & Interview Guide</button>
            </div>

            <div class="categories" id="categories"></div>

            <div class="progress-section">
                <div class="progress-header">
                    <span class="progress-text" id="progressText">Progress: 0/0</span>
                    <button class="reset-btn" onclick="resetProgress()">üîÑ Reset</button>
                </div>
                <div class="progress-bar">
                    <div class="progress-fill" id="progressFill"></div>
                </div>
            </div>

            <div class="card">
                <div>
                    <div class="card-header">
                        <span class="card-number" id="cardNumber">Question 1 of 0</span>
                        <button class="complete-btn" id="completeBtn" onclick="toggleComplete()">Mark Complete</button>
                    </div>

                    <div id="questionContent">
                        <h2 class="question" id="question"></h2>
                        <button class="show-answer-btn" onclick="showAnswer()">Show Answer</button>
                    </div>

                    <div id="answerContent" class="hidden">
                        <h2 class="question" id="questionWithAnswer"></h2>
                        <div class="answer" id="answer"></div>
                    </div>
                </div>

                <div class="navigation">
                    <button class="nav-btn prev" onclick="prevCard()">‚Üê Previous</button>
                    <button class="nav-btn next" onclick="nextCard()">Next ‚Üí</button>
                </div>
            </div>

            <div class="stats" id="stats"></div>
        </div>

        <!-- Resources Content -->
        <div id="resourcesContent" class="hidden">
            <button class="back-btn" onclick="showMain()">‚Üê Back to Flashcards</button>
            <div class="resources">
                <h2>üìö Study Resources & Interview Guide</h2>

                <section>
                    <h3>üìê Essential ML Concepts Explained</h3>
                    
                    <div class="format-item">
                        <h4>Loss Functions - What Are They Measuring?</h4>
                        <p><strong>MSE (Mean Squared Error):</strong> Penalizes predictions quadratically. Big errors get punished MUCH more than small ones because of the square. If you're off by 10, that's 100x worse than being off by 1. Use for regression when you really want to minimize large errors.</p>
                        <p><strong>Cross-Entropy:</strong> Measures "surprise" - how much your predicted probability disagrees with reality. If you predicted 99% confident and were wrong, massive penalty. If you predicted 50-50, smaller penalty. Perfect for classification because it encourages the model to be confidently correct.</p>
                        <p><strong>Hinge Loss:</strong> SVM's loss function. Only cares if you're on the right side of the margin. Once you're confidently correct (margin > 1), the loss is zero. Focuses on "borderline" examples near the decision boundary.</p>
                    </div>

                    <div class="format-item">
                        <h4>Regularization - Why Your Model Needs Boundaries</h4>
                        <p><strong>The Problem:</strong> Without regularization, your model might use HUGE weights to perfectly fit training data, including noise. This kills generalization.</p>
                        <p><strong>L1 (Lasso):</strong> Adds absolute value of weights to loss. Think of it as a "budget" - the model must use weights sparingly. Result? Many weights become exactly zero, giving you automatic feature selection. Great when you suspect only some features matter.</p>
                        <p><strong>L2 (Ridge):</strong> Adds squared weights to loss. Prefers many small weights over few large ones. Doesn't zero out features, just shrinks them proportionally. Better when all features contribute somewhat, or when features are correlated (multicollinearity).</p>
                        <p><strong>Why Œª matters:</strong> Œª is your knob - turn it up for more regularization (simpler model, less overfitting), down for less (more complex, might overfit). Cross-validation finds the sweet spot.</p>
                    </div>

                    <div class="format-item">
                        <h4>Activation Functions - Why Linear Isn't Enough</h4>
                        <p><strong>The Core Problem:</strong> Stacking linear layers just gives you another linear layer. Without non-linearity, neural networks are just fancy linear regression!</p>
                        <p><strong>ReLU (f(x) = max(0, x)):</strong> Dead simple - negative values become 0, positive pass through. Why it works: (1) Gradient is always 1 for positive values (no vanishing gradient!), (2) Induces sparsity (neurons with negative inputs are "off"), (3) Cheap to compute. Downside: "Dying ReLU" - neurons can get stuck at 0.</p>
                        <p><strong>Sigmoid:</strong> Squashes any input to [0,1], interpretable as probability. Problem: Gradients near 0 or 1 are tiny ‚Üí vanishing gradient in deep networks. Mainly used in output layer for binary classification now.</p>
                        <p><strong>Tanh:</strong> Like sigmoid but centered at 0 (output [-1,1]). Better than sigmoid in hidden layers because zero-centered outputs help with convergence. Still has vanishing gradient problem.</p>
                        <p><strong>Softmax:</strong> Takes vector of scores, converts to probability distribution (sums to 1). Each class gets a probability. Higher scores ‚Üí higher probability. Used in output layer for multi-class classification.</p>
                    </div>

                    <div class="format-item">
                        <h4>Gradient Descent Variants - How Does Learning Work?</h4>
                        <p><strong>Core Idea:</strong> Calculate which direction makes loss worse, go opposite direction. Repeat until loss stops decreasing.</p>
                        <p><strong>Batch GD:</strong> Compute gradient using ALL training examples. Pro: Stable, smooth convergence. Con: Slow for big datasets, might need to load everything in memory. Rarely used in practice.</p>
                        <p><strong>Stochastic GD:</strong> Compute gradient using ONE random example. Pro: Fast updates, can escape local minima, works online. Con: Noisy, jumpy convergence, might bounce around optimum.</p>
                        <p><strong>Mini-batch GD:</strong> Compute gradient using small batch (32-512 examples). Sweet spot! Fast enough, stable enough. Can leverage GPU parallelism. This is the standard.</p>
                        <p><strong>Adam:</strong> Adapts learning rate per parameter using moving averages of gradients and squared gradients. Parameters that have been moving consistently get bigger updates. Almost always works out of the box. Default choice for most applications.</p>
                        <p><strong>Learning Rate:</strong> Too high ‚Üí you overshoot and diverge. Too low ‚Üí takes forever. Common strategy: start high (0.001), reduce when progress plateaus (learning rate scheduling).</p>
                    </div>
                </section>

                <section>
                    <h3>üìä Statistics Explained Intuitively</h3>
                    
                    <div class="format-item">
                        <h4>Central Limit Theorem - The Magic of Averages</h4>
                        <p><strong>What it says:</strong> Take ANY distribution (even weird ones), sample from it repeatedly, and average each sample. Plot all these averages, and you get a normal distribution. Mind-blowing!</p>
                        <p><strong>Why it matters:</strong> This is why we can use normal distribution assumptions for hypothesis tests even when our data isn't normal. We're testing means, not individual values.</p>
                        <p><strong>Example:</strong> Roll a die (uniform distribution) 30 times, record average. Do this 1000 times. Your 1000 averages will look like a bell curve centered at 3.5, even though individual rolls are uniform.</p>
                        <p><strong>Requirement:</strong> Sample size n‚â•30 is rule of thumb. Standard error = œÉ/‚àön gets smaller as n grows - more samples = more precise estimate.</p>
                    </div>

                    <div class="format-item">
                        <h4>P-values - The Most Misunderstood Concept</h4>
                        <p><strong>Correct interpretation:</strong> "If the null hypothesis were true, what's the probability of seeing data this extreme or more extreme?"</p>
                        <p><strong>Example:</strong> You claim a coin is biased. Flip it 100 times, get 60 heads. P-value = 0.03 means: "If the coin were fair, only 3% of the time would we get 60+ or 40- heads in 100 flips." That's unlikely, so we doubt the coin is fair.</p>
                        <p><strong>What p-value is NOT:</strong></p>
                        <p>‚ùå "Probability null hypothesis is true" - NO!</p>
                        <p>‚ùå "Probability of Type I error" - NO!</p>
                        <p>‚ùå "Effect size" - NO! p=0.001 doesn't mean huge effect</p>
                        <p><strong>The 0.05 threshold:</strong> Arbitrary convention. P=0.049 isn't fundamentally different from p=0.051. Consider effect size and context!</p>
                    </div>

                    <div class="format-item">
                        <h4>Type I vs Type II Errors - The Trade-off</h4>
                        <p><strong>Type I (False Positive, Œ±):</strong> Crying wolf - saying something's there when it's not. "The treatment works!" when it doesn't. Œ± = 0.05 means we accept 5% false positive rate.</p>
                        <p><strong>Type II (False Negative, Œ≤):</strong> Missing the signal - saying nothing's there when it is. "The treatment doesn't work" when it actually does. Power = 1-Œ≤ is our ability to detect real effects.</p>
                        <p><strong>The Fundamental Trade-off:</strong> Stricter threshold (lower Œ±) ‚Üí harder to claim significance ‚Üí more Type II errors. You can't optimize both simultaneously!</p>
                        <p><strong>Medical Example:</strong> Testing for disease. Type I: Telling healthy person they're sick (false alarm). Type II: Telling sick person they're healthy (missed diagnosis). Which is worse depends on context!</p>
                        <p><strong>Increasing Power:</strong> (1) Larger sample size, (2) Larger effect size (can't control), (3) Lower variability, (4) Higher Œ± (but then more false positives).</p>
                    </div>

                    <div class="format-item">
                        <h4>Confidence Intervals - Better Than P-values</h4>
                        <p><strong>What it means:</strong> "If we repeated this study 100 times, 95 of those intervals would contain the true parameter." NOT "95% chance true value is in this interval."</p>
                        <p><strong>Why better than p-values:</strong> Gives you range of plausible values + uncertainty, not just "significant or not." More information!</p>
                        <p><strong>Example:</strong> Mean height = 170cm, 95% CI [165, 175]. This tells us: (1) Estimate is 170, (2) Precision is ¬±5cm, (3) Values near 165 or 175 are plausible, (4) Values outside range are unlikely.</p>
                        <p><strong>Width tells you precision:</strong> Narrow CI = precise estimate (large n or low variance). Wide CI = uncertain estimate (small n or high variance).</p>
                    </div>
                </section>

                <section>
                    <h3>üíª Coding Patterns Explained</h3>
                    
                    <div class="format-item">
                        <h4>Two Pointers - The Efficiency Hack</h4>
                        <p><strong>Core Idea:</strong> Instead of nested loops (O(n¬≤)), use two pointers moving toward each other or in same direction (O(n)).</p>
                        <p><strong>Classic Example - Two Sum in Sorted Array:</strong> Find pair that sums to target. Start with left=0, right=n-1. If sum too small, move left up. If too big, move right down. Why it works: array is sorted, so we can eliminate half the search space each step!</p>
                        <p><strong>When to Use:</strong> (1) Array/string is sorted or can be sorted, (2) Looking for pairs/triplets, (3) Need to check both ends, (4) Removing duplicates in-place.</p>
                        <p><strong>Common Variations:</strong> Fast-slow pointers (cycle detection in linked list - Floyd's algorithm), sliding window (variable size based on condition).</p>
                        <p><strong>Pro Tip:</strong> If problem mentions "sorted array" or "find pair", think two pointers first!</p>
                    </div>

                    <div class="format-item">
                        <h4>Sliding Window - For Subarray Problems</h4>
                        <p><strong>Core Idea:</strong> Maintain a "window" of elements. Expand right to include new elements, contract left when condition violated. Track best solution seen.</p>
                        <p><strong>Classic Example - Longest Substring Without Repeating Characters:</strong> Use a set to track characters in current window. If new char is duplicate, shrink window from left until duplicate removed. Track max window size. O(n) instead of O(n¬≤)!</p>
                        <p><strong>Two Types:</strong></p>
                        <p>‚Ä¢ Fixed size: "Maximum sum of subarray size k" - slide window by 1, subtract left, add right</p>
                        <p>‚Ä¢ Variable size: "Smallest subarray with sum ‚â• k" - expand until condition met, then contract to minimize</p>
                        <p><strong>When to Use:</strong> Problem asks for continuous subarray/substring with some property. Keywords: "contiguous", "substring", "subarray".</p>
                        <p><strong>Template:</strong> left=0, right=0, expand right in loop, shrink left when condition breaks, track answer.</p>
                    </div>

                    <div class="format-item">
                        <h4>Dynamic Programming - The Art of Remembering</h4>
                        <p><strong>Core Idea:</strong> Break problem into smaller subproblems. Solve each once, remember answer. Use remembered answers to build up to final solution. "Those who forget the past are condemned to recompute it."</p>
                        <p><strong>Classic Example - Fibonacci:</strong> Naive recursion: fib(n) = fib(n-1) + fib(n-2). Recomputes same values exponentially! DP: Save fib(i) in array, look up instead of recompute. O(2‚Åø) ‚Üí O(n)!</p>
                        <p><strong>Two Approaches:</strong></p>
                        <p>‚Ä¢ Top-down (Memoization): Recursive with cache. More intuitive.</p>
                        <p>‚Ä¢ Bottom-up (Tabulation): Iterative, fill table. More efficient, less memory.</p>
                        <p><strong>When to Use:</strong> (1) Optimal substructure (optimal solution contains optimal solutions to subproblems), (2) Overlapping subproblems (same subproblem computed multiple times), (3) Counting problems, optimization problems.</p>
                        <p><strong>Common DP Problems:</strong> Knapsack, longest common subsequence, edit distance, coin change, matrix chain multiplication.</p>
                        <p><strong>How to Recognize:</strong> "Maximum/minimum", "How many ways", "Optimal", problem can be broken into similar smaller problems.</p>
                    </div>
                </section>

                <section>
                    <h3>üìà Quant Finance Explained</h3>
                    
                    <div class="format-item">
                        <h4>Options Basics - What Are You Actually Buying?</h4>
                        <p><strong>Call Option:</strong> Right (not obligation) to BUY stock at strike price K by expiry T. You pay premium upfront. Profit if stock goes up past K + premium.</p>
                        <p><strong>Put Option:</strong> Right to SELL stock at strike price K. Profit if stock goes down below K - premium. Think of it as insurance on your stock.</p>
                        <p><strong>Example:</strong> AAPL is $100. Buy call with K=$110, pay $5 premium. If AAPL hits $120, exercise option: buy at $110, sell at $120, profit = $10 - $5 = $5 per share. If AAPL stays at $100, option expires worthless, lose $5.</p>
                        <p><strong>Why Black-Scholes Matters:</strong> Before B-S, no standard way to price options. B-S gives theoretical fair value based on: stock price S, strike K, time to expiry T, risk-free rate r, volatility œÉ.</p>
                    </div>

                    <div class="format-item">
                        <h4>Black-Scholes Intuition</h4>
                        <p><strong>The Formula:</strong> C = S¬∑N(d‚ÇÅ) - K¬∑e^(-rT)¬∑N(d‚ÇÇ)</p>
                        <p><strong>What it means:</strong> Call price = (Expected stock price if option exercised) - (Discounted strike price weighted by probability of exercise)</p>
                        <p><strong>N(d‚ÇÅ):</strong> Delta, probability of finishing in-the-money adjusted for hedge ratio. How much stock to buy to replicate option.</p>
                        <p><strong>N(d‚ÇÇ):</strong> Actual probability option expires in-the-money (gets exercised).</p>
                        <p><strong>Key Insight:</strong> Higher volatility ‚Üí higher option value. Why? More chance of big move in your favor (upside unlimited), but max loss is premium (limited downside).</p>
                        <p><strong>Assumptions (often violated in reality):</strong> (1) Constant volatility (nope - volatility smile), (2) No dividends (can adjust), (3) Efficient markets (mostly), (4) Lognormal returns (fat tails in reality).</p>
                    </div>
                </section>

                <section>
                    <h3>ü§ñ GenAI/LLM Deep Dive</h3>
                    
                    <div class="format-item">
                        <h4>Transformers - The Revolution Explained</h4>
                        <p><strong>The Problem They Solved:</strong> RNNs process sequences one token at a time (slow!), and struggle with long-range dependencies (attention mechanism tries to fix this but still sequential).</p>
                        <p><strong>The Big Idea:</strong> Process all tokens in parallel using self-attention. Each token looks at ALL other tokens simultaneously and decides which ones are important.</p>
                        <p><strong>Self-Attention Intuition:</strong> For word "it" in "The cat sat on the mat because it was tired", attention helps model figure out "it" refers to "cat" not "mat". It computes: how related is "it" to every other word? High attention to "cat", low to "the", "on", etc.</p>
                        <p><strong>The Math - Attention(Q,K,V) = softmax(QK^T/‚àöd_k)V:</strong></p>
                        <p>‚Ä¢ Q (Query): "What am I looking for?"</p>
                        <p>‚Ä¢ K (Key): "What do I contain?"</p>
                        <p>‚Ä¢ V (Value): "What do I actually output?"</p>
                        <p>‚Ä¢ QK^T: Compute similarity between query and all keys</p>
                        <p>‚Ä¢ /‚àöd_k: Scale to prevent softmax saturation</p>
                        <p>‚Ä¢ softmax: Convert to probability distribution</p>
                        <p>‚Ä¢ Multiply by V: Weighted sum of values</p>
                        <p><strong>Why Multi-Head?</strong> Different heads learn different relationships - one might learn syntax, another semantics, another long-range dependencies. Then concatenate all heads.</p>
                        <p><strong>Position Encodings:</strong> Since attention is permutation-invariant, add position info via sin/cos functions. This tells model "this word came before that word".</p>
                    </div>

                    <div class="format-item">
                        <h4>GPT vs BERT - Two Philosophies</h4>
                        <p><strong>GPT (Generative Pre-trained Transformer):</strong></p>
                        <p>‚Ä¢ Decoder-only architecture, autoregressive (predicts next token)</p>
                        <p>‚Ä¢ Training: "The cat sat on the ___" ‚Üí predict "mat"</p>
                        <p>‚Ä¢ Only sees previous tokens (causal mask prevents looking ahead)</p>
                        <p>‚Ä¢ Use cases: Text generation, completion, chatbots, creative writing</p>
                        <p>‚Ä¢ Scales amazingly - GPT-3, GPT-4 just scaled up same architecture</p>
                        <p><strong>BERT (Bidirectional Encoder):</strong></p>
                        <p>‚Ä¢ Encoder-only, non-autoregressive</p>
                        <p>‚Ä¢ Training: "The [MASK] sat on the mat" ‚Üí predict "cat" using both left and right context</p>
                        <p>‚Ä¢ Sees full context (bidirectional)</p>
                        <p>‚Ä¢ Use cases: Classification, NER, Q&A, sentiment analysis</p>
                        <p>‚Ä¢ Can't generate text (no causal structure)</p>
                        <p><strong>Key Difference:</strong> GPT is like writing - you only know what came before. BERT is like reading - you see the whole sentence. GPT generates, BERT understands.</p>
                        <p><strong>Modern Trend:</strong> GPT-style models winning because generation is harder and more valuable. Can fine-tune GPT for classification too!</p>
                    </div>

                    <div class="format-item">
                        <h4>RAG - Grounding LLMs in Reality</h4>
                        <p><strong>The Hallucination Problem:</strong> LLMs are trained on internet text ‚Üí make up plausible-sounding but wrong facts. They don't "know" what's true vs false, just what's probable.</p>
                        <p><strong>RAG Solution:</strong> Don't rely on model's memory. Give it relevant documents to reference!</p>
                        <p><strong>How It Works:</strong></p>
                        <p>1. <strong>Indexing Phase:</strong> Take your knowledge base (docs, PDFs, etc.), split into chunks (~200-500 tokens), create embeddings for each chunk, store in vector database.</p>
                        <p>2. <strong>Query Phase:</strong> User asks question ‚Üí convert question to embedding ‚Üí find top-k most similar chunks via cosine similarity ‚Üí inject these chunks into the prompt ‚Üí LLM generates answer based on retrieved context.</p>
                        <p><strong>Example:</strong> User: "What's our return policy?" ‚Üí Retrieve: [policy doc chunks] ‚Üí Prompt: "Given these documents: [chunks], answer: What's the return policy?" ‚Üí LLM: "Based on the provided policy, you can return within 30 days..."</p>
                        <p><strong>Benefits:</strong> (1) Reduces hallucinations - grounds in real docs, (2) Up-to-date info without retraining, (3) Citable sources, (4) Works with proprietary data, (5) Easier to debug/fix than changing model.</p>
                        <p><strong>Challenges:</strong> (1) Retrieval quality - if you don't retrieve relevant docs, answer is wrong, (2) Chunk size trade-off - too small loses context, too large exceeds context window, (3) Ranking - semantic similarity ‚â† relevance always.</p>
                        <p><strong>Advanced RAG:</strong> Hybrid search (dense + sparse), reranking, query expansion, recursive retrieval, cite sources in output.</p>
                    </div>
                </section>

                <section>
                    <h3>üéØ ML System Design Framework</h3>
                    
                    <div class="format-item">
                        <h4>1. Clarify Requirements (5 min)</h4>
                        <p><strong>Ask:</strong> What's the goal? Scale (users, QPS)? Latency requirements? Online/offline?</p>
                        <p><strong>Example:</strong> "Is this real-time recommendation or batch? Mobile or web?"</p>
                    </div>

                    <div class="format-item">
                        <h4>2. Define Metrics (5 min)</h4>
                        <p><strong>Business:</strong> Revenue, engagement, conversion</p>
                        <p><strong>ML:</strong> Precision, recall, AUC, NDCG (ranking)</p>
                        <p><strong>System:</strong> Latency (p99), throughput, cost</p>
                    </div>

                    <div class="format-item">
                        <h4>3. High-Level Architecture (10 min)</h4>
                        <p><strong>Components:</strong> Data ‚Üí Features ‚Üí Model ‚Üí Serving ‚Üí Monitoring</p>
                        <p><strong>Draw:</strong> Data sources, feature store, training pipeline, inference</p>
                    </div>

                    <div class="format-item">
                        <h4>4. Data & Features (10 min)</h4>
                        <p><strong>Data sources:</strong> User behavior, item metadata, context</p>
                        <p><strong>Features:</strong> User (age, history), Item (category, popularity), Context (time, device)</p>
                        <p><strong>Engineering:</strong> Normalization, embeddings, feature crosses</p>
                    </div>

                    <div class="format-item">
                        <h4>5. Model Selection (10 min)</h4>
                        <p><strong>Start simple:</strong> Logistic regression, collaborative filtering</p>
                        <p><strong>Iterate:</strong> Deep learning (two-tower, transformers)</p>
                        <p><strong>Consider:</strong> Cold start, diversity, exploration vs exploitation</p>
                    </div>

                    <div class="format-item">
                        <h4>6. Training & Evaluation (10 min)</h4>
                        <p><strong>Train/val/test split:</strong> Time-based for temporal data</p>
                        <p><strong>Offline eval:</strong> AUC, precision@k, NDCG</p>
                        <p><strong>Online eval:</strong> A/B testing, interleaving</p>
                        <p><strong>Retraining:</strong> Frequency, triggers, incremental learning</p>
                    </div>

                    <div class="format-item">
                        <h4>7. Serving & Infrastructure (5 min)</h4>
                        <p><strong>Serving:</strong> REST API, batch processing, caching</p>
                        <p><strong>Latency:</strong> Model size, quantization, model distillation</p>
                        <p><strong>Scaling:</strong> Load balancing, horizontal scaling, CDN</p>
                    </div>

                    <div class="format-item">
                        <h4>8. Monitoring & Debugging (5 min)</h4>
                        <p><strong>Monitor:</strong> Model performance, data drift, prediction distribution</p>
                        <p><strong>Alerts:</strong> Accuracy drop, latency spike, null predictions</p>
                        <p><strong>Debug:</strong> Feature importance, error analysis, user feedback</p>
                    </div>
                </section>

                <section>
                    <h3>üó£Ô∏è Behavioral Interview Guide (STAR Method)</h3>
                    
                    <div class="format-item">
                        <h4>STAR Framework</h4>
                        <p><strong>Situation:</strong> Set the context (15-20%)</p>
                        <p><strong>Task:</strong> Describe your responsibility (15-20%)</p>
                        <p><strong>Action:</strong> What YOU did, be specific (50%)</p>
                        <p><strong>Result:</strong> Outcome, metrics, learnings (15-20%)</p>
                    </div>

                    <div class="format-item">
                        <h4>Common Questions & Approach</h4>
                        <p><strong>"Tell me about a challenging project"</strong></p>
                        <p>‚Üí Pick project with technical depth, show problem-solving</p>
                        <p><strong>"Describe a time you failed"</strong></p>
                        <p>‚Üí Real failure, focus on learnings, what you'd do differently</p>
                        <p><strong>"How do you handle disagreement?"</strong></p>
                        <p>‚Üí Show data-driven approach, respect for others, compromise</p>
                        <p><strong>"Why ML/this company?"</strong></p>
                        <p>‚Üí Genuine interest, specific examples, align with values</p>
                    </div>

                    <div class="format-item">
                        <h4>Prepare 5 Core Stories</h4>
                        <p><strong>1. Technical achievement:</strong> Complex ML project, impact</p>
                        <p><strong>2. Leadership/influence:</strong> Led initiative, mentored, drove decision</p>
                        <p><strong>3. Failure/learning:</strong> What went wrong, what you learned</p>
                        <p><strong>4. Collaboration:</strong> Worked across teams, resolved conflict</p>
                        <p><strong>5. Innovation:</strong> Creative solution, new approach</p>
                    </div>
                </section>

                <section>
                    <h3>üìÖ Final Week Checklist</h3>
                    
                    <div class="timeline-item blue">
                        <h4>7 Days Before</h4>
                        <p>‚úÖ Review all flashcards one final time</p>
                        <p>‚úÖ Do 2-3 practice problems (confidence boost, not learning)</p>
                        <p>‚úÖ Review your projects, prepare to explain deeply</p>
                    </div>
                    
                    <div class="timeline-item green">
                        <h4>3 Days Before</h4>
                        <p>‚úÖ Mock interview with friend/platform</p>
                        <p>‚úÖ Test your setup (camera, mic, internet)</p>
                        <p>‚úÖ Prepare questions to ask interviewer (5-10)</p>
                    </div>
                    
                    <div class="timeline-item orange">
                        <h4>1 Day Before</h4>
                        <p>‚úÖ Light review of formulas only</p>
                        <p>‚úÖ Get 8+ hours of sleep</p>
                        <p>‚úÖ Prepare clothes, workspace</p>
                        <p>‚úÖ NO new material</p>
                    </div>
                    
                    <div class="timeline-item red">
                        <h4>Interview Day</h4>
                        <p>‚úÖ Eat a good meal 2 hours before</p>
                        <p>‚úÖ Arrive/join 10 minutes early</p>
                        <p>‚úÖ Have water, paper, pen ready</p>
                        <p>‚úÖ Take deep breaths, you've got this! üí™</p>
                    </div>
                </section>
            </div>
        </div>
    </div>

    <script>
        // Data
        const questions = {
            'ml-theory': [
                { q: "What is the bias-variance tradeoff?", a: "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias (underfitting) means the model is too simple and makes strong assumptions. High variance (overfitting) means the model is too complex and captures noise. The goal is to find the sweet spot that minimizes total error = bias¬≤ + variance + irreducible error." },
                { q: "Explain the difference between L1 and L2 regularization.", a: "L1 (Lasso) adds the absolute value of coefficients as penalty (Œª‚àë|w|), promoting sparsity and feature selection. L2 (Ridge) adds the square of coefficients (Œª‚àëw¬≤), shrinking all coefficients but rarely to zero. L1 is better for feature selection; L2 is better when all features are relevant." },
                { q: "What is gradient descent and why might it fail?", a: "Gradient descent iteratively updates parameters in the direction of steepest descent: w = w - Œ±‚àáL(w). It can fail due to: 1) Getting stuck in local minima (less common in high dimensions), 2) Poor learning rate (too high causes divergence, too low causes slow convergence), 3) Saddle points in high dimensions, 4) Vanishing/exploding gradients." },
                { q: "Explain precision vs recall with an example.", a: "Precision = TP/(TP+FP) - of predicted positives, how many are correct. Recall = TP/(TP+FN) - of actual positives, how many did we find. Example: Email spam filter. High precision = few false alarms (good emails marked spam). High recall = catches most spam (but might flag good emails too). F1-score balances both." },
                { q: "What is cross-validation and why use it?", a: "Cross-validation splits data into k folds, trains on k-1 and validates on 1, rotating through all folds. Benefits: 1) Better estimate of model performance on unseen data, 2) Uses all data for both training and validation, 3) Reduces variance in performance estimate. Common: 5-fold or 10-fold CV." }
            ],
            'deep-learning': [
                { q: "Why do we need non-linear activation functions?", a: "Without non-linearity, stacking multiple layers would just create another linear transformation. No matter how many linear layers you stack, the composition is still linear: f(g(x)) = Ax + b for some A and b. Non-linear activations allow networks to learn complex, non-linear patterns and decision boundaries. This is what makes deep learning 'deep' - each layer can learn increasingly abstract features." },
                { q: "What causes vanishing/exploding gradients and how do we fix them?", a: "Vanishing: Gradients become exponentially smaller as they propagate backward through layers. Caused by: repeated multiplication of small derivatives (sigmoid/tanh < 1), deep networks. Solutions: ReLU activation (gradient = 1), batch normalization, residual connections (ResNet), proper initialization (Xavier/He). Exploding: Gradients grow exponentially. Caused by: large weights, deep networks. Solutions: Gradient clipping, proper initialization, batch normalization, LSTM/GRU for sequences." },
                { q: "How does Batch Normalization work and why is it effective?", a: "BatchNorm normalizes inputs to each layer to have mean=0, std=1 across the mini-batch: BN(x) = Œ≥((x-Œº_batch)/œÉ_batch) + Œ≤. Benefits: 1) Faster training (can use higher learning rates), 2) Reduces internal covariate shift (stabilizes distributions), 3) Acts as regularization (batch statistics add noise), 4) Less sensitive to initialization. During inference, uses running averages from training. Applied before or after activation function (debated)." },
                { q: "When would you use SGD over Adam optimizer?", a: "SGD often achieves better final model quality (generalizes better) but converges slower. Adam converges faster but can get stuck in sharp minima (poor generalization). Use SGD when: 1) Final model quality is critical, 2) Have time for longer training, 3) Computer vision tasks (empirically better). Use Adam when: 1) Quick prototyping, 2) NLP/sequence tasks, 3) Need robust to hyperparameters. Common practice: Start with Adam for exploration, switch to SGD+momentum for final training." },
                { q: "Describe common learning rate schedules and when to use them.", a: "Step Decay: Reduce LR by factor every N epochs. Simple, works well. Cosine Annealing: Smooth decay following cosine curve. Good for known training duration. Warm-up: Start with low LR, increase linearly. Critical for transformers (stability with large batches). Cyclic: Oscillate between min/max LR. Helps escape local minima. ReduceLROnPlateau: Reduce when validation loss plateaus. Adaptive, no manual scheduling. Exponential: LR = LR‚ÇÄ * decay^epoch. Smooth continuous decay." },
                { q: "Rank regularization techniques by effectiveness.", a: "Generally (but task-dependent): 1) More data (always best if possible), 2) Data augmentation (free performance boost), 3) Dropout (simple, effective for fully connected layers), 4) Early stopping (prevents overfitting automatically), 5) Weight decay/L2 (helps but limited impact), 6) Smaller model (if other methods insufficient). Modern additions: MixUp, CutMix (advanced augmentation), StochDepth (dropping layers), DropConnect. Key: Combine multiple techniques for best results." },
                { q: "Why are CNNs better than fully connected networks for images?", a: "1) Parameter sharing: Same filter applied across entire image (millions fewer parameters). 2) Translation invariance: Can detect features anywhere in image. 3) Hierarchical features: Early layers learn edges, later layers learn complex objects. 4) Local connectivity: Pixels near each other are related (spatial structure). Example: 224√ó224√ó3 image. Fully connected: 150K parameters per neuron! Conv layer with 32 3√ó3 filters: only 896 parameters. Massive efficiency gain while preserving spatial information." },
                { q: "How do you calculate receptive field size?", a: "Receptive field = region in input that affects a particular output. Formula: RF = 1 + Œ£(kernel_size - 1) √ó Œ†(strides). For layer l: RF_l = RF_{l-1} + (kernel_size - 1) √ó Œ†(strides from 1 to l-1). Example: Two 3√ó3 conv layers, stride 1: RF = 1 + 2 + 2 = 5√ó5. With 2√ó2 pooling between: RF = 1 + 2 + 2√ó2 = 7√ó7. Deeper layers see exponentially larger regions. Can increase via: larger kernels, pooling, dilated convolutions, more layers." },
                { q: "Trace the evolution: AlexNet ‚Üí ResNet ‚Üí EfficientNet", a: "AlexNet (2012): First deep CNN to win ImageNet. 8 layers, ReLU, dropout, data augmentation. Proved deep learning works. VGG (2014): Uniform 3√ó3 filters, deeper (16-19 layers). Simple but effective. ResNet (2015): Skip connections solve vanishing gradients. 152+ layers possible! Identity mappings: y = F(x) + x. EfficientNet (2019): Compound scaling - jointly scale depth, width, resolution. Neural architecture search for base model. SOTA efficiency. Key insight: Balanced scaling beats just going deeper." },
                { q: "What's the key difference between LSTM and GRU?", a: "LSTM has separate memory cell and hidden state, with 3 gates (forget, input, output). GRU combines memory and hidden state into single state, with 2 gates (reset, update). GRU update gate combines LSTM's forget and input gates. Performance similar, but GRU has 33% fewer parameters, trains faster. LSTM: Better for complex long-term patterns. GRU: Better with limited data. Both solve vanishing gradient via gating mechanisms that control information flow." },
                { q: "When can't you use bidirectional RNNs?", a: "Can't use when future context isn't available: 1) Real-time/streaming applications (live transcription, online translation), 2) Autoregressive generation (next token prediction), 3) Online decision making (trading, control systems), 4) Causal time series forecasting. Bidirectional requires full sequence available - processes forward and backward. Great for: sequence labeling (NER, POS), machine translation (offline), sentiment analysis. Alternative for online: Use unidirectional with attention mechanism or transformers with causal masking." },
                { q: "How did attention improve seq2seq models before transformers?", a: "Original seq2seq compressed entire input to single context vector - information bottleneck! Attention allows decoder to look at all encoder hidden states, not just final one. At each decoder step: 1) Compare decoder state with all encoder states (scores), 2) Softmax to get weights, 3) Weighted sum of encoder states. Benefits: Handles long sequences better, provides alignment (what translates to what), interpretable. Bahdanau attention (2014) improved BLEU scores significantly. This paved the way for self-attention and transformers." },
                { q: "Explain SimCLR in simple terms.", a: "SimCLR learns representations without labels via contrastive learning. Process: 1) Take image, create two augmented views (crop, color distort, etc.), 2) Encode both views with same network, 3) Project to embedding space, 4) Pull same-image embeddings together, push different-image embeddings apart. Loss: NT-Xent (normalized temperature cross-entropy). Key insights: Strong augmentation crucial, large batch size important (more negatives), projection head helps, no need for memory banks. Achieves near-supervised performance. Used for: Pre-training when labels scarce, transfer learning." },
                { q: "How do you distill a large model to a small one?", a: "Knowledge Distillation transfers 'dark knowledge' from teacher to student. Process: 1) Train large teacher model normally, 2) Generate soft predictions (logits) from teacher, 3) Train student to match: Œ±√óCrossEntropy(student, true_labels) + (1-Œ±)√óKL(student_soft, teacher_soft). Temperature T softens probabilities: p_i = exp(z_i/T)/Œ£exp(z_j/T). Higher T reveals more about relative probabilities. Dark knowledge: Relationships between classes (dog more similar to cat than to car). Student often achieves 90%+ of teacher performance at fraction of size." },
                { q: "What are the main Neural Architecture Search approaches?", a: "1) Reinforcement Learning: Controller network proposes architectures, trains them, uses accuracy as reward. Expensive but flexible. 2) Evolutionary Algorithms: Population of architectures, mutation/crossover, select best. Intuitive but slow. 3) Differentiable (DARTS): Continuous relaxation of architecture search. All operations in supermodel, learn importance weights. Fast (days vs months). 4) One-shot/Weight-sharing: Train single supermodel, sample subnetworks. Efficient but biased. Modern: Combining methods, hardware-aware search, once-for-all networks. Challenge: Huge search spaces, evaluation cost." },
                { q: "Model loss not decreasing - debugging steps?", a: "Systematic debugging: 1) Verify data pipeline (shape, type, preprocessing, no NaNs), 2) Check loss calculation (correct function, reduction), 3) Verify gradients flowing (not zero, not exploding), 4) Learning rate (try 10x smaller and larger), 5) Overfit single batch first (should get ~0 loss), 6) Simpler model/problem first, 7) Check initialization (not all zeros), 8) Remove regularization temporarily, 9) Gradient clipping if exploding, 10) Visualize weights/gradients/activations. Tools: TensorBoard, gradient hooks, print statements. Most common: Wrong LR, bug in data pipeline, incorrect loss function." },
                { q: "How does mixed precision (FP16) training work?", a: "Use FP16 for forward/backward passes, FP32 master weights for updates. Benefits: 2√ó memory reduction, 2-3√ó speedup on modern GPUs (Tensor Cores). Three key techniques: 1) Master weights in FP32 (accumulate small updates), 2) Loss scaling (prevent gradient underflow - multiply loss by large number, divide gradients), 3) Dynamic loss scaling (adjust scale based on gradient overflow). Automatic with torch.cuda.amp or tf.keras.mixed_precision. Works for most models, struggles with very small gradients. Critical for large models (fits bigger batch, model)." },
                { q: "Data parallel vs Model parallel?", a: "Data Parallel: Split batch across GPUs, each GPU has full model copy. Forward on subset, average gradients, synchronize. Simple, efficient for most cases. Limited by model size fitting on single GPU. Model Parallel: Split model layers across GPUs. GPU 1 has layers 1-5, GPU 2 has 6-10, etc. Sequential dependencies cause idle time ('bubble'). Use when model doesn't fit on one GPU. Pipeline Parallel: Model parallel + microbatches to reduce idle time. Tensor Parallel: Split individual layers (for huge layers). Modern: Combine all approaches (3D parallelism)." },
                { q: "How do you apply convolution to graphs (GNNs)?", a: "Can't use regular conv - graphs have irregular structure (variable neighbors). Solution: Aggregate neighbor features (message passing). Basic formulation: h_i' = œÉ(W_self¬∑h_i + Œ£(W_neighbor¬∑h_j) for j in neighbors(i)). Popular approaches: 1) GCN: Normalized aggregation with self-loops, 2) GraphSAGE: Sample fixed-size neighborhoods, various aggregators, 3) GAT: Attention-based weighting of neighbors. Key idea: Local aggregation + neural network = powerful graph learning. Applications: Social networks, molecules, recommendation systems." },
                { q: "Key difference between autoencoder and VAE?", a: "Autoencoder: Deterministic encoding/decoding. Encoder: x ‚Üí z (single point). Decoder: z ‚Üí xÃÇ. Just compresses and reconstructs. VAE: Probabilistic - learns distribution. Encoder: x ‚Üí Œº, œÉ (parameters of distribution). Sample: z ~ N(Œº, œÉ). Decoder: z ‚Üí xÃÇ. Loss = Reconstruction + KL divergence (regularizes latent space). Benefits of VAE: 1) Can generate new samples (sample from prior), 2) Smooth latent space (interpolation meaningful), 3) Principled probabilistic framework. Autoencoders just compress, VAEs learn data generation process." },
                { q: "How would you improve a CNN model? (systematic approach)", a: "Ordered by impact/effort: 1) Data: More data, better augmentation (MixUp, CutMix, RandAugment), fix label noise, balance classes. 2) Architecture: Deeper/wider (if underfitting), add regularization (if overfitting), try proven architectures (ResNet, EfficientNet), attention mechanisms. 3) Training: Tune learning rate (most important!), longer training with decay, different optimizer, gradient clipping. 4) Regularization: Dropout, weight decay, stochastic depth, label smoothing. 5) Ensemble: Multiple models, test-time augmentation. 6) Advanced: Knowledge distillation, semi-supervised learning, self-supervised pretraining. Always: Establish strong baseline first, change one thing at a time, track experiments carefully." },
                { q: "Explain this to a non-technical person: Backpropagation", a: "Imagine teaching a child to throw darts. After each throw, you see how far off the target they were (the error). You then figure out what adjustments to make: elbow position, wrist angle, force. Backpropagation works similarly - the network makes a prediction, sees how wrong it was, then works backward to figure out how to adjust each 'knob' (weight) to do better next time. It's like having a coach for each tiny decision in the network, all coordinating to improve the final result. The 'back' part means we start from the error and work backward to the beginning." },
                { q: "What's your approach to debugging a deep learning model?", a: "Start simple, build complexity: 1) Verify data pipeline (visualize batches, check preprocessing), 2) Start with tiny model on tiny data (should overfit perfectly), 3) Gradually increase complexity, 4) Monitor everything (loss curves, gradients, activations, weights), 5) Common issues checklist: learning rate (try 10x range), initialization, gradient flow, data leaks, 6) Ablation studies (remove components to isolate issues), 7) Compare to known working baseline, 8) Unit test critical components. Key principle: Make it work on simple case first, then scale. Most bugs are in data pipeline or hyperparameters, not the model architecture." }
            ],
            'statistics': [
                { q: "Explain the Central Limit Theorem.", a: "The CLT states that the sampling distribution of the sample mean approaches a normal distribution as sample size increases, regardless of the population's distribution (given finite variance). Key points: 1) Sample size n‚â•30 typically sufficient, 2) Mean of sampling distribution = population mean, 3) Std dev = œÉ/‚àön. Critical for hypothesis testing and confidence intervals." },
                { q: "What is a p-value and how do you interpret it?", a: "A p-value is the probability of observing data at least as extreme as what we got, assuming the null hypothesis is true. Low p-value (typically <0.05) suggests strong evidence against null hypothesis. NOT the probability that null is true. Common misconceptions: p=0.05 isn't a magical threshold, statistical significance ‚â† practical significance." }
            ],
            'coding': [
                { q: "Implement k-means clustering from scratch.", a: "def kmeans(X, k, max_iters=100):\n  centroids = X[np.random.choice(len(X), k, replace=False)]\n  for _ in range(max_iters):\n    distances = np.sqrt(((X[:, None] - centroids) ** 2).sum(axis=2))\n    labels = distances.argmin(axis=1)\n    new_centroids = np.array([X[labels == i].mean(axis=0) for i in range(k)])\n    if np.allclose(centroids, new_centroids): break\n    centroids = new_centroids\n  return labels, centroids" },
                { q: "Write a function to compute cosine similarity.", a: "def cosine_similarity(a, b):\n  return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n\n# Range: [-1, 1]\n# 1 = identical direction\n# -1 = opposite\n# 0 = orthogonal" }
            ],
            'quant': [
                { q: "Expected coin flips for two heads in a row?", a: "Let E = expected flips from start, E_H = expected flips after seeing one H. E = 1 + 0.5*E_H + 0.5*E (if T, restart). E_H = 1 + 0.5*0 + 0.5*E (if HH done, if HT restart). Solving: E_H = 1 + 0.5*E. Substituting: E = 1 + 0.5*(1 + 0.5*E) + 0.5*E = 1.5 + 0.75*E. Answer: E = 6 flips." },
                { q: "Explain the Sharpe ratio.", a: "Sharpe Ratio = (R_p - R_f) / œÉ_p measures return per unit of total volatility. R_p = portfolio return, R_f = risk-free rate, œÉ_p = portfolio std dev. Higher is better. Drawback: treats upside and downside volatility equally. Alternative: Sortino ratio (uses only downside deviation)." }
            ],
            'genai': [
                { q: "Explain the transformer architecture.", a: "Transformers use self-attention to process sequences in parallel. Key components: 1) Multi-head self-attention: Attention(Q,K,V) = softmax(QK^T/‚àöd_k)V, 2) Position encoding (sine/cosine), 3) Feed-forward networks, 4) Layer normalization and residual connections. Why revolutionary: parallelizable, better long-range dependencies, scalable, transfer learning." },
                { q: "What's the difference between GPT and BERT?", a: "GPT: Decoder-only, autoregressive, left-to-right. Training: next token prediction. Use: generation. BERT: Encoder-only, bidirectional. Training: masked language modeling (MLM). Use: classification, NER, Q&A. Key: GPT sees only past, BERT sees past+future. GPT better for generation, BERT for understanding. Modern: GPT-style models winning." }
            ]
        };

        const categories = {
            'ml-theory': { name: 'ML Theory', icon: 'üß†', color: 'blue' },
            'deep-learning': { name: 'Deep Learning', icon: 'üî•', color: 'red' },
            'statistics': { name: 'Statistics', icon: 'üìä', color: 'green' },
            'coding': { name: 'Coding', icon: 'üíª', color: 'purple' },
            'quant': { name: 'Quant/Finance', icon: 'üìà', color: 'orange' },
            'genai': { name: 'GenAI/LLMs', icon: 'ü§ñ', color: 'pink' }
        };

        // State
        let activeCategory = 'ml-theory';
        let currentCard = 0;
        let showingAnswer = false;
        let completedCards = new Set();

        // Initialize
        function init() {
            renderCategories();
            renderCard();
            updateStats();
        }

        function renderCategories() {
            const container = document.getElementById('categories');
            container.innerHTML = '';
            
            Object.entries(categories).forEach(([key, data]) => {
                const btn = document.createElement('button');
                btn.className = `category-btn ${data.color}`;
                if (key === activeCategory) btn.classList.add('active');
                btn.textContent = `${data.icon} ${data.name}`;
                btn.onclick = () => switchCategory(key);
                container.appendChild(btn);
            });
        }

        function switchCategory(key) {
            activeCategory = key;
            currentCard = 0;
            showingAnswer = false;
            renderCategories();
            renderCard();
            updateStats();
        }

        function renderCard() {
            const qs = questions[activeCategory];
            const q = qs[currentCard];
            
            document.getElementById('cardNumber').textContent = `Question ${currentCard + 1} of ${qs.length}`;
            document.getElementById('question').textContent = q.q;
            document.getElementById('questionWithAnswer').textContent = q.q;
            document.getElementById('answer').textContent = q.a;
            
            const completeBtn = document.getElementById('completeBtn');
            const key = `${activeCategory}-${currentCard}`;
            if (completedCards.has(key)) {
                completeBtn.classList.add('completed');
                completeBtn.textContent = '‚úì Mastered';
            } else {
                completeBtn.classList.remove('completed');
                completeBtn.textContent = 'Mark Complete';
            }
            
            if (showingAnswer) {
                document.getElementById('questionContent').classList.add('hidden');
                document.getElementById('answerContent').classList.remove('hidden');
            } else {
                document.getElementById('questionContent').classList.remove('hidden');
                document.getElementById('answerContent').classList.add('hidden');
            }
            
            updateProgress();
        }

        function showAnswer() {
            showingAnswer = true;
            renderCard();
        }

        function nextCard() {
            const qs = questions[activeCategory];
            currentCard = (currentCard + 1) % qs.length;
            showingAnswer = false;
            renderCard();
        }

        function prevCard() {
            const qs = questions[activeCategory];
            currentCard = (currentCard - 1 + qs.length) % qs.length;
            showingAnswer = false;
            renderCard();
        }

        function toggleComplete() {
            const key = `${activeCategory}-${currentCard}`;
            if (completedCards.has(key)) {
                completedCards.delete(key);
            } else {
                completedCards.add(key);
            }
            renderCard();
            updateStats();
        }

        function updateProgress() {
            const qs = questions[activeCategory];
            const completed = Array.from(completedCards).filter(k => k.startsWith(activeCategory)).length;
            const total = qs.length;
            const percent = (completed / total) * 100;
            
            document.getElementById('progressText').textContent = `Progress: ${completed}/${total}`;
            document.getElementById('progressFill').style.width = `${percent}%`;
        }

        function updateStats() {
            const container = document.getElementById('stats');
            container.innerHTML = '';
            
            Object.entries(categories).forEach(([key, data]) => {
                const completed = Array.from(completedCards).filter(k => k.startsWith(key)).length;
                const total = questions[key].length;
                
                const card = document.createElement('div');
                card.className = 'stat-card';
                card.innerHTML = `
                    <div class="stat-icon">${data.icon}</div>
                    <div class="stat-name">${data.name}</div>
                    <div class="stat-value ${data.color}">${completed}/${total}</div>
                `;
                container.appendChild(card);
            });
            
            updateProgress();
        }

        function resetProgress() {
            if (confirm('Reset all progress?')) {
                completedCards.clear();
                currentCard = 0;
                showingAnswer = false;
                renderCard();
                updateStats();
            }
        }

        function showResources() {
            document.getElementById('mainContent').classList.add('hidden');
            document.getElementById('resourcesContent').classList.remove('hidden');
        }

        function showMain() {
            document.getElementById('mainContent').classList.remove('hidden');
            document.getElementById('resourcesContent').classList.add('hidden');
        }

        // Start the app
        init();
    </script>
</body>
</html>
