<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ML/DS/Quant Interview Prep</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #f5f7fa 0%, #e4e9f2 100%);
            min-height: 100vh;
            padding: 20px;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
        }
        
        .header {
            text-align: center;
            margin-bottom: 40px;
        }
        
        .header h1 {
            font-size: 2.5rem;
            color: #1e293b;
            margin-bottom: 10px;
        }
        
        .header p {
            color: #64748b;
            font-size: 1.1rem;
        }
        
        .resource-btn {
            margin-top: 15px;
            padding: 12px 24px;
            background: #f97316;
            color: white;
            border: none;
            border-radius: 8px;
            font-size: 1rem;
            cursor: pointer;
            transition: background 0.3s;
        }
        
        .resource-btn:hover {
            background: #ea580c;
        }
        
        .categories {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            justify-content: center;
            margin-bottom: 30px;
        }
        
        .category-btn {
            padding: 12px 20px;
            border: none;
            border-radius: 8px;
            font-size: 1rem;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.3s;
            background: white;
            color: #334155;
        }
        
        .category-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0,0,0,0.1);
        }
        
        .category-btn.active {
            color: white;
            box-shadow: 0 4px 12px rgba(0,0,0,0.15);
        }
        
        .category-btn.blue.active { background: #3b82f6; }
        .category-btn.red.active { background: #ef4444; }
        .category-btn.green.active { background: #10b981; }
        .category-btn.purple.active { background: #8b5cf6; }
        .category-btn.orange.active { background: #f97316; }
        .category-btn.pink.active { background: #ec4899; }
        
        .progress-section {
            background: white;
            padding: 20px;
            border-radius: 12px;
            margin-bottom: 30px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }
        
        .progress-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 10px;
        }
        
        .progress-text {
            font-weight: 500;
            color: #334155;
        }
        
        .reset-btn {
            background: none;
            border: none;
            color: #64748b;
            cursor: pointer;
            font-size: 0.9rem;
        }
        
        .reset-btn:hover {
            color: #334155;
        }
        
        .progress-bar {
            width: 100%;
            height: 12px;
            background: #e2e8f0;
            border-radius: 6px;
            overflow: hidden;
        }
        
        .progress-fill {
            height: 100%;
            background: #3b82f6;
            transition: width 0.3s ease;
            border-radius: 6px;
        }
        
        .card {
            background: white;
            border-radius: 16px;
            padding: 40px;
            margin-bottom: 30px;
            min-height: 400px;
            box-shadow: 0 4px 16px rgba(0,0,0,0.1);
            display: flex;
            flex-direction: column;
            justify-content: space-between;
        }
        
        .card-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 20px;
        }
        
        .card-number {
            color: #64748b;
            font-size: 0.9rem;
        }
        
        .complete-btn {
            padding: 8px 16px;
            border: none;
            border-radius: 6px;
            font-size: 0.9rem;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.3s;
            background: #f1f5f9;
            color: #64748b;
        }
        
        .complete-btn:hover {
            background: #e2e8f0;
        }
        
        .complete-btn.completed {
            background: #dcfce7;
            color: #166534;
        }
        
        .question {
            font-size: 1.5rem;
            font-weight: 700;
            color: #1e293b;
            margin-bottom: 20px;
            line-height: 1.4;
        }
        
        .answer {
            background: #f8fafc;
            padding: 20px;
            border-radius: 8px;
            color: #334155;
            line-height: 1.7;
            white-space: pre-line;
            margin-top: 20px;
        }
        
        .show-answer-btn {
            padding: 12px 24px;
            background: #3b82f6;
            color: white;
            border: none;
            border-radius: 8px;
            font-size: 1rem;
            font-weight: 500;
            cursor: pointer;
            transition: background 0.3s;
            margin-top: 20px;
        }
        
        .show-answer-btn:hover {
            background: #2563eb;
        }
        
        .navigation {
            display: flex;
            justify-content: space-between;
            margin-top: 30px;
        }
        
        .nav-btn {
            padding: 12px 24px;
            border: none;
            border-radius: 8px;
            font-size: 1rem;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.3s;
        }
        
        .nav-btn.prev {
            background: #e2e8f0;
            color: #334155;
        }
        
        .nav-btn.prev:hover:not(:disabled) {
            background: #cbd5e1;
        }
        
        .nav-btn.next {
            background: #334155;
            color: white;
        }
        
        .nav-btn.next:hover {
            background: #1e293b;
        }
        
        .nav-btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }
        
        .stats {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 15px;
        }
        
        .stat-card {
            background: white;
            padding: 20px;
            border-radius: 12px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
            text-align: center;
        }
        
        .stat-icon {
            font-size: 2rem;
            margin-bottom: 8px;
        }
        
        .stat-name {
            font-size: 0.85rem;
            color: #64748b;
            margin-bottom: 5px;
        }
        
        .stat-value {
            font-size: 1.2rem;
            font-weight: 700;
        }
        
        .stat-value.blue { color: #3b82f6; }
        .stat-value.red { color: #ef4444; }
        .stat-value.green { color: #10b981; }
        .stat-value.purple { color: #8b5cf6; }
        .stat-value.orange { color: #f97316; }
        .stat-value.pink { color: #ec4899; }
        
        .resources {
            background: white;
            border-radius: 16px;
            padding: 40px;
            box-shadow: 0 4px 16px rgba(0,0,0,0.1);
        }
        
        .resources h2 {
            font-size: 2rem;
            color: #1e293b;
            margin-bottom: 30px;
        }
        
        .resources h3 {
            font-size: 1.3rem;
            color: #1e293b;
            margin-top: 25px;
            margin-bottom: 15px;
        }
        
        .resources section {
            margin-bottom: 30px;
        }
        
        .resources ul {
            list-style: disc;
            padding-left: 25px;
            color: #64748b;
            line-height: 1.8;
        }
        
        .resources p {
            color: #64748b;
            line-height: 1.7;
            margin-bottom: 10px;
        }
        
        .timeline-item, .format-item {
            padding: 15px;
            border-radius: 8px;
            margin-bottom: 15px;
        }
        
        .timeline-item h4, .format-item h4 {
            font-weight: 700;
            margin-bottom: 8px;
        }
        
        .timeline-item.blue { background: #dbeafe; color: #1e40af; }
        .timeline-item.green { background: #d1fae5; color: #065f46; }
        .timeline-item.orange { background: #fed7aa; color: #9a3412; }
        .timeline-item.red { background: #fee2e2; color: #991b1b; }
        
        .format-item { background: #f8fafc; color: #334155; }
        
        .back-btn {
            padding: 12px 24px;
            background: #475569;
            color: white;
            border: none;
            border-radius: 8px;
            font-size: 1rem;
            cursor: pointer;
            margin-bottom: 30px;
            transition: background 0.3s;
        }
        
        .back-btn:hover {
            background: #334155;
        }
        
        .hidden {
            display: none;
        }
        
        @media (max-width: 768px) {
            .header h1 {
                font-size: 1.8rem;
            }
            
            .card {
                padding: 25px;
                min-height: 350px;
            }
            
            .question {
                font-size: 1.2rem;
            }
            
            .stats {
                grid-template-columns: repeat(2, 1fr);
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <!-- Main Content -->
        <div id="mainContent">
            <div class="header">
                <h1>🎯 Interview Prep Hub</h1>
                <p>ML • Deep Learning • Data Science • GenAI • Quant Finance</p>
                <button class="resource-btn" onclick="showResources()">📚 Study Resources & Interview Guide</button>
            </div>

            <div class="categories" id="categories"></div>

            <div class="progress-section">
                <div class="progress-header">
                    <span class="progress-text" id="progressText">Progress: 0/0</span>
                    <button class="reset-btn" onclick="resetProgress()">🔄 Reset</button>
                </div>
                <div class="progress-bar">
                    <div class="progress-fill" id="progressFill"></div>
                </div>
            </div>

            <div class="card">
                <div>
                    <div class="card-header">
                        <span class="card-number" id="cardNumber">Question 1 of 0</span>
                        <button class="complete-btn" id="completeBtn" onclick="toggleComplete()">Mark Complete</button>
                    </div>

                    <div id="questionContent">
                        <h2 class="question" id="question"></h2>
                        <button class="show-answer-btn" onclick="showAnswer()">Show Answer</button>
                    </div>

                    <div id="answerContent" class="hidden">
                        <h2 class="question" id="questionWithAnswer"></h2>
                        <div class="answer" id="answer"></div>
                    </div>
                </div>

                <div class="navigation">
                    <button class="nav-btn prev" onclick="prevCard()">← Previous</button>
                    <button class="nav-btn next" onclick="nextCard()">Next →</button>
                </div>
            </div>

            <div class="stats" id="stats"></div>
        </div>

        <!-- Resources Content -->
        <div id="resourcesContent" class="hidden">
            <button class="back-btn" onclick="showMain()">← Back to Flashcards</button>
            <div class="resources">
                <!-- Resources content here - keeping minimal for space -->
                <h2>📚 Study Resources & Interview Guide</h2>
                <p>Complete study materials and guides are available in the flashcards.</p>
            </div>
        </div>
    </div>

    <script>
        // Data
        const questions = {
            'ml-theory': [
                { q: "What is the bias-variance tradeoff?", a: "The bias-variance tradeoff describes the relationship between model complexity and prediction error. High bias (underfitting) means the model is too simple and makes strong assumptions. High variance (overfitting) means the model is too complex and captures noise. The goal is to find the sweet spot that minimizes total error = bias² + variance + irreducible error." },
                { q: "Explain the difference between L1 and L2 regularization.", a: "L1 (Lasso) adds the absolute value of coefficients as penalty (λ∑|w|), promoting sparsity and feature selection. L2 (Ridge) adds the square of coefficients (λ∑w²), shrinking all coefficients but rarely to zero. L1 is better for feature selection; L2 is better when all features are relevant." },
                { q: "What is gradient descent and why might it fail?", a: "Gradient descent iteratively updates parameters in the direction of steepest descent: w = w - α∇L(w). It can fail due to: 1) Getting stuck in local minima (less common in high dimensions), 2) Poor learning rate (too high causes divergence, too low causes slow convergence), 3) Saddle points in high dimensions, 4) Vanishing/exploding gradients." },
                { q: "Explain precision vs recall with an example.", a: "Precision = TP/(TP+FP) - of predicted positives, how many are correct. Recall = TP/(TP+FN) - of actual positives, how many did we find. Example: Email spam filter. High precision = few false alarms (good emails marked spam). High recall = catches most spam (but might flag good emails too). F1-score balances both." },
                { q: "What is cross-validation and why use it?", a: "Cross-validation splits data into k folds, trains on k-1 and validates on 1, rotating through all folds. Benefits: 1) Better estimate of model performance on unseen data, 2) Uses all data for both training and validation, 3) Reduces variance in performance estimate. Common: 5-fold or 10-fold CV." }
            ],
            'deep-learning': [
                { q: "Why do we need non-linear activation functions?", a: "Without non-linearity, stacking multiple layers would just create another linear transformation. No matter how many linear layers you stack, the composition is still linear: f(g(x)) = Ax + b for some A and b. Non-linear activations allow networks to learn complex, non-linear patterns and decision boundaries. This is what makes deep learning 'deep' - each layer can learn increasingly abstract features." },
                { q: "What causes vanishing/exploding gradients and how do we fix them?", a: "Vanishing: Gradients become exponentially smaller as they propagate backward through layers. Caused by: repeated multiplication of small derivatives (sigmoid/tanh < 1), deep networks. Solutions: ReLU activation (gradient = 1), batch normalization, residual connections (ResNet), proper initialization (Xavier/He). Exploding: Gradients grow exponentially. Caused by: large weights, deep networks. Solutions: Gradient clipping, proper initialization, batch normalization, LSTM/GRU for sequences." },
                { q: "How does Batch Normalization work and why is it effective?", a: "BatchNorm normalizes inputs to each layer to have mean=0, std=1 across the mini-batch: BN(x) = γ((x-μ_batch)/σ_batch) + β. Benefits: 1) Faster training (can use higher learning rates), 2) Reduces internal covariate shift (stabilizes distributions), 3) Acts as regularization (batch statistics add noise), 4) Less sensitive to initialization. During inference, uses running averages from training. Applied before or after activation function (debated)." },
                { q: "When would you use SGD over Adam optimizer?", a: "SGD often achieves better final model quality (generalizes better) but converges slower. Adam converges faster but can get stuck in sharp minima (poor generalization). Use SGD when: 1) Final model quality is critical, 2) Have time for longer training, 3) Computer vision tasks (empirically better). Use Adam when: 1) Quick prototyping, 2) NLP/sequence tasks, 3) Need robust to hyperparameters. Common practice: Start with Adam for exploration, switch to SGD+momentum for final training." },
                { q: "Describe common learning rate schedules and when to use them.", a: "Step Decay: Reduce LR by factor every N epochs. Simple, works well. Cosine Annealing: Smooth decay following cosine curve. Good for known training duration. Warm-up: Start with low LR, increase linearly. Critical for transformers (stability with large batches). Cyclic: Oscillate between min/max LR. Helps escape local minima. ReduceLROnPlateau: Reduce when validation loss plateaus. Adaptive, no manual scheduling. Exponential: LR = LR₀ * decay^epoch. Smooth continuous decay." },
                { q: "Rank regularization techniques by effectiveness.", a: "Generally (but task-dependent): 1) More data (always best if possible), 2) Data augmentation (free performance boost), 3) Dropout (simple, effective for fully connected layers), 4) Early stopping (prevents overfitting automatically), 5) Weight decay/L2 (helps but limited impact), 6) Smaller model (if other methods insufficient). Modern additions: MixUp, CutMix (advanced augmentation), StochDepth (dropping layers), DropConnect. Key: Combine multiple techniques for best results." },
                { q: "Why are CNNs better than fully connected networks for images?", a: "1) Parameter sharing: Same filter applied across entire image (millions fewer parameters). 2) Translation invariance: Can detect features anywhere in image. 3) Hierarchical features: Early layers learn edges, later layers learn complex objects. 4) Local connectivity: Pixels near each other are related (spatial structure). Example: 224×224×3 image. Fully connected: 150K parameters per neuron! Conv layer with 32 3×3 filters: only 896 parameters. Massive efficiency gain while preserving spatial information." },
                { q: "How do you calculate receptive field size?", a: "Receptive field = region in input that affects a particular output. Formula: RF = 1 + Σ(kernel_size - 1) × Π(strides). For layer l: RF_l = RF_{l-1} + (kernel_size - 1) × Π(strides from 1 to l-1). Example: Two 3×3 conv layers, stride 1: RF = 1 + 2 + 2 = 5×5. With 2×2 pooling between: RF = 1 + 2 + 2×2 = 7×7. Deeper layers see exponentially larger regions. Can increase via: larger kernels, pooling, dilated convolutions, more layers." },
                { q: "Trace the evolution: AlexNet → ResNet → EfficientNet", a: "AlexNet (2012): First deep CNN to win ImageNet. 8 layers, ReLU, dropout, data augmentation. Proved deep learning works. VGG (2014): Uniform 3×3 filters, deeper (16-19 layers). Simple but effective. ResNet (2015): Skip connections solve vanishing gradients. 152+ layers possible! Identity mappings: y = F(x) + x. EfficientNet (2019): Compound scaling - jointly scale depth, width, resolution. Neural architecture search for base model. SOTA efficiency. Key insight: Balanced scaling beats just going deeper." },
                { q: "What's the key difference between LSTM and GRU?", a: "LSTM has separate memory cell and hidden state, with 3 gates (forget, input, output). GRU combines memory and hidden state into single state, with 2 gates (reset, update). GRU update gate combines LSTM's forget and input gates. Performance similar, but GRU has 33% fewer parameters, trains faster. LSTM: Better for complex long-term patterns. GRU: Better with limited data. Both solve vanishing gradient via gating mechanisms that control information flow." },
                { q: "When can't you use bidirectional RNNs?", a: "Can't use when future context isn't available: 1) Real-time/streaming applications (live transcription, online translation), 2) Autoregressive generation (next token prediction), 3) Online decision making (trading, control systems), 4) Causal time series forecasting. Bidirectional requires full sequence available - processes forward and backward. Great for: sequence labeling (NER, POS), machine translation (offline), sentiment analysis. Alternative for online: Use unidirectional with attention mechanism or transformers with causal masking." },
                { q: "How did attention improve seq2seq models before transformers?", a: "Original seq2seq compressed entire input to single context vector - information bottleneck! Attention allows decoder to look at all encoder hidden states, not just final one. At each decoder step: 1) Compare decoder state with all encoder states (scores), 2) Softmax to get weights, 3) Weighted sum of encoder states. Benefits: Handles long sequences better, provides alignment (what translates to what), interpretable. Bahdanau attention (2014) improved BLEU scores significantly. This paved the way for self-attention and transformers." },
                { q: "Explain SimCLR in simple terms.", a: "SimCLR learns representations without labels via contrastive learning. Process: 1) Take image, create two augmented views (crop, color distort, etc.), 2) Encode both views with same network, 3) Project to embedding space, 4) Pull same-image embeddings together, push different-image embeddings apart. Loss: NT-Xent (normalized temperature cross-entropy). Key insights: Strong augmentation crucial, large batch size important (more negatives), projection head helps, no need for memory banks. Achieves near-supervised performance. Used for: Pre-training when labels scarce, transfer learning." },
                { q: "How do you distill a large model to a small one?", a: "Knowledge Distillation transfers 'dark knowledge' from teacher to student. Process: 1) Train large teacher model normally, 2) Generate soft predictions (logits) from teacher, 3) Train student to match: α×CrossEntropy(student, true_labels) + (1-α)×KL(student_soft, teacher_soft). Temperature T softens probabilities: p_i = exp(z_i/T)/Σexp(z_j/T). Higher T reveals more about relative probabilities. Dark knowledge: Relationships between classes (dog more similar to cat than to car). Student often achieves 90%+ of teacher performance at fraction of size." },
                { q: "What are the main Neural Architecture Search approaches?", a: "1) Reinforcement Learning: Controller network proposes architectures, trains them, uses accuracy as reward. Expensive but flexible. 2) Evolutionary Algorithms: Population of architectures, mutation/crossover, select best. Intuitive but slow. 3) Differentiable (DARTS): Continuous relaxation of architecture search. All operations in supermodel, learn importance weights. Fast (days vs months). 4) One-shot/Weight-sharing: Train single supermodel, sample subnetworks. Efficient but biased. Modern: Combining methods, hardware-aware search, once-for-all networks. Challenge: Huge search spaces, evaluation cost." },
                { q: "Model loss not decreasing - debugging steps?", a: "Systematic debugging: 1) Verify data pipeline (shape, type, preprocessing, no NaNs), 2) Check loss calculation (correct function, reduction), 3) Verify gradients flowing (not zero, not exploding), 4) Learning rate (try 10x smaller and larger), 5) Overfit single batch first (should get ~0 loss), 6) Simpler model/problem first, 7) Check initialization (not all zeros), 8) Remove regularization temporarily, 9) Gradient clipping if exploding, 10) Visualize weights/gradients/activations. Tools: TensorBoard, gradient hooks, print statements. Most common: Wrong LR, bug in data pipeline, incorrect loss function." },
                { q: "How does mixed precision (FP16) training work?", a: "Use FP16 for forward/backward passes, FP32 master weights for updates. Benefits: 2× memory reduction, 2-3× speedup on modern GPUs (Tensor Cores). Three key techniques: 1) Master weights in FP32 (accumulate small updates), 2) Loss scaling (prevent gradient underflow - multiply loss by large number, divide gradients), 3) Dynamic loss scaling (adjust scale based on gradient overflow). Automatic with torch.cuda.amp or tf.keras.mixed_precision. Works for most models, struggles with very small gradients. Critical for large models (fits bigger batch, model)." },
                { q: "Data parallel vs Model parallel?", a: "Data Parallel: Split batch across GPUs, each GPU has full model copy. Forward on subset, average gradients, synchronize. Simple, efficient for most cases. Limited by model size fitting on single GPU. Model Parallel: Split model layers across GPUs. GPU 1 has layers 1-5, GPU 2 has 6-10, etc. Sequential dependencies cause idle time ('bubble'). Use when model doesn't fit on one GPU. Pipeline Parallel: Model parallel + microbatches to reduce idle time. Tensor Parallel: Split individual layers (for huge layers). Modern: Combine all approaches (3D parallelism)." },
                { q: "How do you apply convolution to graphs (GNNs)?", a: "Can't use regular conv - graphs have irregular structure (variable neighbors). Solution: Aggregate neighbor features (message passing). Basic formulation: h_i' = σ(W_self·h_i + Σ(W_neighbor·h_j) for j in neighbors(i)). Popular approaches: 1) GCN: Normalized aggregation with self-loops, 2) GraphSAGE: Sample fixed-size neighborhoods, various aggregators, 3) GAT: Attention-based weighting of neighbors. Key idea: Local aggregation + neural network = powerful graph learning. Applications: Social networks, molecules, recommendation systems." },
                { q: "Key difference between autoencoder and VAE?", a: "Autoencoder: Deterministic encoding/decoding. Encoder: x → z (single point). Decoder: z → x̂. Just compresses and reconstructs. VAE: Probabilistic - learns distribution. Encoder: x → μ, σ (parameters of distribution). Sample: z ~ N(μ, σ). Decoder: z → x̂. Loss = Reconstruction + KL divergence (regularizes latent space). Benefits of VAE: 1) Can generate new samples (sample from prior), 2) Smooth latent space (interpolation meaningful), 3) Principled probabilistic framework. Autoencoders just compress, VAEs learn data generation process." },
                { q: "How would you improve a CNN model? (systematic approach)", a: "Ordered by impact/effort: 1) Data: More data, better augmentation (MixUp, CutMix, RandAugment), fix label noise, balance classes. 2) Architecture: Deeper/wider (if underfitting), add regularization (if overfitting), try proven architectures (ResNet, EfficientNet), attention mechanisms. 3) Training: Tune learning rate (most important!), longer training with decay, different optimizer, gradient clipping. 4) Regularization: Dropout, weight decay, stochastic depth, label smoothing. 5) Ensemble: Multiple models, test-time augmentation. 6) Advanced: Knowledge distillation, semi-supervised learning, self-supervised pretraining. Always: Establish strong baseline first, change one thing at a time, track experiments carefully." },
                { q: "Explain this to a non-technical person: Backpropagation", a: "Imagine teaching a child to throw darts. After each throw, you see how far off the target they were (the error). You then figure out what adjustments to make: elbow position, wrist angle, force. Backpropagation works similarly - the network makes a prediction, sees how wrong it was, then works backward to figure out how to adjust each 'knob' (weight) to do better next time. It's like having a coach for each tiny decision in the network, all coordinating to improve the final result. The 'back' part means we start from the error and work backward to the beginning." },
                { q: "What's your approach to debugging a deep learning model?", a: "Start simple, build complexity: 1) Verify data pipeline (visualize batches, check preprocessing), 2) Start with tiny model on tiny data (should overfit perfectly), 3) Gradually increase complexity, 4) Monitor everything (loss curves, gradients, activations, weights), 5) Common issues checklist: learning rate (try 10x range), initialization, gradient flow, data leaks, 6) Ablation studies (remove components to isolate issues), 7) Compare to known working baseline, 8) Unit test critical components. Key principle: Make it work on simple case first, then scale. Most bugs are in data pipeline or hyperparameters, not the model architecture." }
            ],
            'statistics': [
                { q: "Explain the Central Limit Theorem.", a: "The CLT states that the sampling distribution of the sample mean approaches a normal distribution as sample size increases, regardless of the population's distribution (given finite variance). Key points: 1) Sample size n≥30 typically sufficient, 2) Mean of sampling distribution = population mean, 3) Std dev = σ/√n. Critical for hypothesis testing and confidence intervals." },
                { q: "What is a p-value and how do you interpret it?", a: "A p-value is the probability of observing data at least as extreme as what we got, assuming the null hypothesis is true. Low p-value (typically <0.05) suggests strong evidence against null hypothesis. NOT the probability that null is true. Common misconceptions: p=0.05 isn't a magical threshold, statistical significance ≠ practical significance." }
            ],
            'coding': [
                { q: "Implement k-means clustering from scratch.", a: "def kmeans(X, k, max_iters=100):\n  centroids = X[np.random.choice(len(X), k, replace=False)]\n  for _ in range(max_iters):\n    distances = np.sqrt(((X[:, None] - centroids) ** 2).sum(axis=2))\n    labels = distances.argmin(axis=1)\n    new_centroids = np.array([X[labels == i].mean(axis=0) for i in range(k)])\n    if np.allclose(centroids, new_centroids): break\n    centroids = new_centroids\n  return labels, centroids" },
                { q: "Write a function to compute cosine similarity.", a: "def cosine_similarity(a, b):\n  return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n\n# Range: [-1, 1]\n# 1 = identical direction\n# -1 = opposite\n# 0 = orthogonal" }
            ],
            'quant': [
                { q: "Expected coin flips for two heads in a row?", a: "Let E = expected flips from start, E_H = expected flips after seeing one H. E = 1 + 0.5*E_H + 0.5*E (if T, restart). E_H = 1 + 0.5*0 + 0.5*E (if HH done, if HT restart). Solving: E_H = 1 + 0.5*E. Substituting: E = 1 + 0.5*(1 + 0.5*E) + 0.5*E = 1.5 + 0.75*E. Answer: E = 6 flips." },
                { q: "Explain the Sharpe ratio.", a: "Sharpe Ratio = (R_p - R_f) / σ_p measures return per unit of total volatility. R_p = portfolio return, R_f = risk-free rate, σ_p = portfolio std dev. Higher is better. Drawback: treats upside and downside volatility equally. Alternative: Sortino ratio (uses only downside deviation)." }
            ],
            'genai': [
                { q: "Explain the transformer architecture.", a: "Transformers use self-attention to process sequences in parallel. Key components: 1) Multi-head self-attention: Attention(Q,K,V) = softmax(QK^T/√d_k)V, 2) Position encoding (sine/cosine), 3) Feed-forward networks, 4) Layer normalization and residual connections. Why revolutionary: parallelizable, better long-range dependencies, scalable, transfer learning." },
                { q: "What's the difference between GPT and BERT?", a: "GPT: Decoder-only, autoregressive, left-to-right. Training: next token prediction. Use: generation. BERT: Encoder-only, bidirectional. Training: masked language modeling (MLM). Use: classification, NER, Q&A. Key: GPT sees only past, BERT sees past+future. GPT better for generation, BERT for understanding. Modern: GPT-style models winning." }
            ]
        };

        const categories = {
            'ml-theory': { name: 'ML Theory', icon: '🧠', color: 'blue' },
            'deep-learning': { name: 'Deep Learning', icon: '🔥', color: 'red' },
            'statistics': { name: 'Statistics', icon: '📊', color: 'green' },
            'coding': { name: 'Coding', icon: '💻', color: 'purple' },
            'quant': { name: 'Quant/Finance', icon: '📈', color: 'orange' },
            'genai': { name: 'GenAI/LLMs', icon: '🤖', color: 'pink' }
        };

        // State
        let activeCategory = 'ml-theory';
        let currentCard = 0;
        let showingAnswer = false;
        let completedCards = new Set();

        // Initialize
        function init() {
            renderCategories();
            renderCard();
            updateStats();
        }

        function renderCategories() {
            const container = document.getElementById('categories');
            container.innerHTML = '';
            
            Object.entries(categories).forEach(([key, data]) => {
                const btn = document.createElement('button');
                btn.className = `category-btn ${data.color}`;
                if (key === activeCategory) btn.classList.add('active');
                btn.textContent = `${data.icon} ${data.name}`;
                btn.onclick = () => switchCategory(key);
                container.appendChild(btn);
            });
        }

        function switchCategory(key) {
            activeCategory = key;
            currentCard = 0;
            showingAnswer = false;
            renderCategories();
            renderCard();
            updateStats();
        }

        function renderCard() {
            const qs = questions[activeCategory];
            const q = qs[currentCard];
            
            document.getElementById('cardNumber').textContent = `Question ${currentCard + 1} of ${qs.length}`;
            document.getElementById('question').textContent = q.q;
            document.getElementById('questionWithAnswer').textContent = q.q;
            document.getElementById('answer').textContent = q.a;
            
            const completeBtn = document.getElementById('completeBtn');
            const key = `${activeCategory}-${currentCard}`;
            if (completedCards.has(key)) {
                completeBtn.classList.add('completed');
                completeBtn.textContent = '✓ Mastered';
            } else {
                completeBtn.classList.remove('completed');
                completeBtn.textContent = 'Mark Complete';
            }
            
            if (showingAnswer) {
                document.getElementById('questionContent').classList.add('hidden');
                document.getElementById('answerContent').classList.remove('hidden');
            } else {
                document.getElementById('questionContent').classList.remove('hidden');
                document.getElementById('answerContent').classList.add('hidden');
            }
            
            updateProgress();
        }

        function showAnswer() {
            showingAnswer = true;
            renderCard();
        }

        function nextCard() {
            const qs = questions[activeCategory];
            currentCard = (currentCard + 1) % qs.length;
            showingAnswer = false;
            renderCard();
        }

        function prevCard() {
            const qs = questions[activeCategory];
            currentCard = (currentCard - 1 + qs.length) % qs.length;
            showingAnswer = false;
            renderCard();
        }

        function toggleComplete() {
            const key = `${activeCategory}-${currentCard}`;
            if (completedCards.has(key)) {
                completedCards.delete(key);
            } else {
                completedCards.add(key);
            }
            renderCard();
            updateStats();
        }

        function updateProgress() {
            const qs = questions[activeCategory];
            const completed = Array.from(completedCards).filter(k => k.startsWith(activeCategory)).length;
            const total = qs.length;
            const percent = (completed / total) * 100;
            
            document.getElementById('progressText').textContent = `Progress: ${completed}/${total}`;
            document.getElementById('progressFill').style.width = `${percent}%`;
        }

        function updateStats() {
            const container = document.getElementById('stats');
            container.innerHTML = '';
            
            Object.entries(categories).forEach(([key, data]) => {
                const completed = Array.from(completedCards).filter(k => k.startsWith(key)).length;
                const total = questions[key].length;
                
                const card = document.createElement('div');
                card.className = 'stat-card';
                card.innerHTML = `
                    <div class="stat-icon">${data.icon}</div>
                    <div class="stat-name">${data.name}</div>
                    <div class="stat-value ${data.color}">${completed}/${total}</div>
                `;
                container.appendChild(card);
            });
            
            updateProgress();
        }

        function resetProgress() {
            if (confirm('Reset all progress?')) {
                completedCards.clear();
                currentCard = 0;
                showingAnswer = false;
                renderCard();
                updateStats();
            }
        }

        function showResources() {
            document.getElementById('mainContent').classList.add('hidden');
            document.getElementById('resourcesContent').classList.remove('hidden');
        }

        function showMain() {
            document.getElementById('mainContent').classList.remove('hidden');
            document.getElementById('resourcesContent').classList.add('hidden');
        }

        // Start the app
        init();
    </script>
</body>
</html>
